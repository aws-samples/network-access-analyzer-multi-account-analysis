AWSTemplateFormatVersion: "2010-09-09"
Description: >
  Deploys an EC2 Instance, S3 bucket, and IAM Cross-Account trusted Role for use with the Network Access Analyzer script. 
  Userdata has a bash script embedded which will be used for multi-account scanning. 
  Note that $ and ` in Userdata are escaped with \ if they are not supposed to be interpreted by CloudFormation

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "Network Configuration"
        Parameters:
          - VpcId
          - SubnetId
      - Label:
          default: "EC2 Configuration"
        Parameters:
          - InstanceType
          - InstanceImageId
          - KeyPairName
          - PermittedSSHInbound
      - Label:
          default: "S3 Configuration"
        Parameters:
          - BucketName
      - Label:
          default: "SNS Configuration"
        Parameters:
          - EmailAddress          
      - Label:
          default: "IAM Configuration"
        Parameters:
          - IAMNAAEC2Role
          - IAMNAAExecRole
      - Label:
          default: "Network Access Analzyer Script Parameters"
        Parameters:
          - Parallelism
          - Regions
          - ScopeNameValue
          - ExclusionsFile
          - ScheduledAnalysis
          - CronScheduleExpression

Parameters:
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: Select a VPC
  SubnetId:
    Type: AWS::EC2::Subnet::Id
    Description: Select a private subnet with Internet access. (Userdata is dependent on Internet for downloading binaries during EC2 provisioning)
  InstanceImageId:
    Type: "AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>"
    Description: Amazon Linux 2 Image
    Default: "/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2"
  InstanceType:
    Type: String
    Default: t3.small
    AllowedValues:
      - t3.small
      - t2.small
    Description: "Specify the instance size to use"
  BucketName:
    Type: String
    Description: Specify the Bucket Name for the NAA output and exception file download (Account ID and Region will be appended e.g. naa-<AccountID>-<region>)
    Default: naa
  EmailAddress:
    Type: String
    Description: "Optional: If you wish to receive a notification when NAA is completed and has uploaded the zip file containing findings, enter an email address and accept the topic subscription before NAA completes the assessment"
  IAMNAAEC2Role:
    Type: "String"
    Description: "Name of IAM Role to be created for use with the NAA EC2 Instance. This role's ARN is used with the NAAExecRole CFN template"
    Default: "NAAEC2Role"
  IAMNAAExecRole:
    Type: "String"
    Description: "Name of IAM Role to be assumed in the member accounts. This name must match the IAM Role deployed via the NAAExecRole CFN template"
    Default: "NAAExecRole"
  Parallelism:
    Type: String
    Description: "Specify the number of accounts to assess in parallel"
    Default: 10
    AllowedValues:
      - 10
      - 12
      - 14
  Regions:
    Type: String
    Description: "Specify the regions which will be analyzed.  Use space separation when listing multiple regions (e.g. us-east-1 us-east-2)"
    Default: us-east-1
  KeyPairName:
    Type: "String"
    Description: "Optional: Specify the name of a pre-existing EC2 KeyPair if you require ssh to the NAA instance.  Recommendation is to leave blank and use SSM Connect"
  PermittedSSHInbound:
    Type: "String"
    Description: "Optional: If allowing inbound SSH, specify the permitted CIDR else leave the default 127.0.0.1"
    Default: "127.0.0.1/32"
  ScopeNameValue:
    Type: "String"
    Description: "Name of Network Access Analyzer scope tag which is assigned during deployment"
    Default: "naa-external-ingress"
  ExclusionsFile:
    Type: "String"
    Description: "Name of the exclusions file which is used to exclude findings from CSV output"
    Default: "naa-exclusions.csv"
  ScheduledAnalysis:
    Type: "String"
    Description: "Schedule automated analysis via cron. If true, the CronScheduleExpression parameter is used, else it is ignored (Note: After initial EC2 provisioning, /etc/cron.d/naa-schedule mus be manually deleted to remove the cron schedule)"
    Default: "true"
    AllowedValues:
      - true
      - false
  CronScheduleExpression:
    Type: "String"
    Description: "Specify the frequency of Network Access Analzyer analysis via cron expression (e.g. Midnight on Sunday 0 0 * * 0 OR Midnight on First Sunday of each month 0 0 * 1-12 0) (Note: After initial EC2 provisioning, /etc/cron.d/naa-schedule must manually adjusted)"
    Default: "0 0 * * 0"

Mappings: 
  PartitionMap: 
    aws:
      ec2service: ec2.amazonaws.com
    aws-us-gov:
      ec2service: ec2.amazonaws.com
    aws-cn:
      ec2service: ec2.amazonaws.com.cn

Conditions:
  KeyProvided:
    Fn::Not:
      - Fn::Equals:
          - ""
          - Ref: KeyPairName

  EmailProvided:
    Fn::Not:
      - Fn::Equals:
          - ""
          - Ref: EmailAddress

Resources:
  NAAEC2RolePolicy:
    Type: "AWS::IAM::ManagedPolicy"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W13
            reason: "The resource must remain as * in order to list accounts in the AWS Org."
          - id: W28
            reason: "The IAM Role name is specified as an explicit for use within the scripting"
    Properties:
      Description: "This policy grants necessary permissions to assume NAAExecRole in AWS accounts"
      ManagedPolicyName: !Sub "${IAMNAAEC2Role}Policy"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Resource: !Sub "arn:${AWS::Partition}:iam::*:role/${IAMNAAExecRole}"
          - Effect: Allow
            Sid: ActionsPermittedForScriptAccountListGenerationREQUIRED
            Action:
              - "organizations:DescribeOrganization"
            Resource: "*"
          - Effect: Allow
            Sid: AllowS3BucketPutObject
            Action:
              - "s3:PutObject"
              - "s3:GetObject"
            Resource: !Sub "arn:${AWS::Partition}:s3:::${S3Bucket}/*"
      Roles:
        - Ref: "IAMNAAEC2Role"

  NAAEC2Role:
    Type: "AWS::IAM::Role"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28
            reason: "The IAM Role name is specified as an explicit for use within the scripting"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service:
                - !FindInMap [PartitionMap, !Ref "AWS::Partition", ec2service]
            Action:
              - "sts:AssumeRole"
      Description: "This role grants necessary permissions for the NAA Script EC2 instance to assume roles in accounts"
      ManagedPolicyArns:
        - !Sub "arn:${AWS::Partition}:iam::${AWS::Partition}:policy/AmazonSSMManagedInstanceCore"
      Path: "/"
      RoleName: !Sub "${IAMNAAEC2Role}"

  RootInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      InstanceProfileName: !Sub "${IAMNAAEC2Role}"
      Path: "/"
      Roles:
        - Ref: "IAMNAAEC2Role"

  NAASNSTopic:
    Condition: EmailProvided
    Type: AWS::SNS::Topic
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W47
            reason: "The SNS Topic is used to send a notification when the NAA analysis is completed and objects are uploaded to S3"
    Properties:
      TopicName: NAANotifications

  NAASNSSubscription:
    Condition: EmailProvided
    Type: AWS::SNS::Subscription
    Properties:
      Protocol: email
      Endpoint: !Ref EmailAddress
      TopicArn: !Ref NAASNSTopic
      
  NAASNSTopicPolicy:
    Condition: EmailProvided
    Type: AWS::SNS::TopicPolicy
    Properties:
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: events.amazonaws.com
            Action:
              - sns:Publish
            Resource:
              Ref: NAASNSTopic
            Condition:
              StringEquals:
                aws:SourceAccount: !Sub "${AWS::AccountId}"
      Topics:
        - !Ref NAASNSTopic

  S3EventRule:
    Condition: EmailProvided
    Type: "AWS::Events::Rule"
    Properties:
      Description: NAA S3 Bucket Event
      Name: NAAS3BucketEvent
      EventPattern:
        source:
          - aws.s3
        detail-type:
          - Object Created
        detail:
          bucket:
            name:
            - !Ref S3Bucket
          object:
            key:
              - anything-but: !Ref ExclusionsFile
      State: ENABLED
      Targets:
        - Arn: !Ref NAASNSTopic
          Id: NAASNSTopic
          InputTransformer:
            InputPathsMap:
              "s3bucket": "$.detail.bucket.name"
              "s3objectkey": "$.detail.object.key"
            InputTemplate: |
              "NAA asessment has completed and the report has been uploaded to the S3 Bucket."
              "Please download and process the findings"
              "S3 Bucket Name: <s3bucket>"
              "S3 Object Key: <s3objectkey>"
          RetryPolicy:
            MaximumRetryAttempts: 4
            MaximumEventAgeInSeconds: 400

  NAASG:
    Type: "AWS::EC2::SecurityGroup"
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W28
            reason: "The Security Group name is specified explicitly."
          - id: W5
            reason: "The Security Group has egress rules with cidr open to world to download packages from repos."
    Properties:
      GroupDescription: "Security Group which allows outbound Internet and SSM access"
      VpcId: !Ref VpcId
      SecurityGroupEgress:
        - Description: "Download packages from Internet, SSM Connect, and write to S3"
          IpProtocol: "tcp"
          FromPort: "443"
          ToPort: "443"
          CidrIp: 0.0.0.0/0
        - Description: "DNS resolution"
          IpProtocol: "udp"
          FromPort: "53"
          ToPort: "53"
          CidrIp: 0.0.0.0/0
      SecurityGroupIngress:
        - Description: "Inbound SSH"
          IpProtocol: "tcp"
          FromPort: "22"
          ToPort: "22"
          CidrIp: !Ref PermittedSSHInbound
      GroupName: "naa-sg"
      Tags:
        - Key: "Name"
          Value: "naa-sg"

  S3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3Bucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              AWS: !GetAtt NAAEC2Role.Arn
            Action:
              - "s3:PutObject"
              - "s3:GetObject"
            Resource: !Sub "arn:${AWS::Partition}:s3:::${S3Bucket}/*"
          - Sid: Deny non-HTTPS access
            Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - !Sub "arn:${AWS::Partition}:s3:::${S3Bucket}"
              - !Sub "arn:${AWS::Partition}:s3:::${S3Bucket}/*"
            Condition:
              Bool:
                aws:SecureTransport: "false"

  S3Bucket:
    Type: "AWS::S3::Bucket"
    Properties:
      BucketName: !Sub "${BucketName}-${AWS::AccountId}-${AWS::Region}"
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LoggingBucket
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      OwnershipControls:
        Rules:
          - ObjectOwnership: BucketOwnerEnforced
      NotificationConfiguration:
        EventBridgeConfiguration:
          EventBridgeEnabled: true
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: "Name"
          Value: !Sub "${BucketName}-${AWS::AccountId}-${AWS::Region}"

  S3LoggingBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3LoggingBucket
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: Deny non-HTTPS access
            Effect: Deny
            Principal: "*"
            Action: s3:*
            Resource:
              - !Sub "arn:${AWS::Partition}:s3:::${S3LoggingBucket}"
              - !Sub "arn:${AWS::Partition}:s3:::${S3LoggingBucket}/*"
            Condition:
              Bool:
                aws:SecureTransport: "false"

  S3LoggingBucket:
    Type: 'AWS::S3::Bucket'
    Metadata:
      cfn_nag:
        rules_to_suppress:
          - id: W35
            reason: "S3 access logging is not enable as this is the logging bucket"
    Properties:
      AccessControl: LogDeliveryWrite
      BucketName: !Sub "${BucketName}-accesslogs-${AWS::AccountId}-${AWS::Region}"
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      LifecycleConfiguration:
        Rules:
        - Id: LoggingLifeCycle
          Status: Enabled
          ExpirationInDays: '180'
          NoncurrentVersionExpirationInDays: '180'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: "Name"
          Value: !Sub "${BucketName}-access-logs-${AWS::AccountId}-${AWS::Region}"

  LaunchTemplate:
    Type: "AWS::EC2::LaunchTemplate"
    Properties:
      LaunchTemplateData:
        MetadataOptions:
          HttpTokens: "required"

  Ec2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId:
        Ref: "InstanceImageId"
      InstanceType: !Ref InstanceType
      BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: "12"
            DeleteOnTermination: true
            VolumeType: "gp3"
            Encrypted: true
      SubnetId: !Ref SubnetId
      IamInstanceProfile: !Ref IAMNAAEC2Role
      LaunchTemplate:
        LaunchTemplateId:
          Ref: "LaunchTemplate"
        Version: "1"
      KeyName:
        Fn::If:
          - KeyProvided
          - Ref: KeyPairName
          - Ref: AWS::NoValue
      SecurityGroupIds:
        - !GetAtt "NAASG.GroupId"
      UserData:
        Fn::Base64:
          Fn::Sub: |
            #!/bin/bash
            yum upgrade -y
            
            #Install script dependencies
            yum install -y jq pip

            yum remove -y awscli
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            ./aws/install
            ln -s /usr/local/bin/aws /usr/local/sbin/aws
            pip3 install csvkit
            ln -s /usr/local/bin/csvjoin /usr/bin

            mkdir /usr/local/bin/naa

            #Download the python finding conversion script 
            wget -P /usr/local/bin/naa https://raw.githubusercontent.com/aws-samples/network-access-analyzer-multi-account-analysis/main/naa-findings2csv.py

            #Create the naa-script.sh and use CloudFormation substitution during deployment
            tee -a /usr/local/bin/naa/naa-script.sh <<EOL
            #!/bin/bash

            #Variable Descriptions:
            #   1) SPECIFIC_ACCOUNTID_LIST: List specific accounts (SPACE DELIMITED) if you wish to run the command only against those
            #        or leave "allaccounts" to detect and execute against all accounts in the AWS Org
            #   2) REGION_LIST (SPACE DELIMITED): Specify regions to analyze with Network Access Analyzer
            #   3) IAM_CROSS_ACCOUNT_ROLE: The IAM Role name created for cross account execution
            #   4) SCRIPT_EXECUTION_MODE:
            #       Specify CREATE_ANALYZE to direct the script to create Network Access Analyzer scopes (if they don't exist already) and analyze them
            #       Specify DELETE to direct the script to delete Network Access Analyzer scopes which have been provisioned (located by scope name tag)
            #       In order to REDEPLOY scopes, utilize delete to remove all scopes, modify the Network Access Analyzer JSON file, and then execute with CREATE_ANALYZE
            #   5) Configure SCOPE_NAME_VALUE to specify the name tag which will be assigned to the scope. This tag is used to locate the scope for analysis
            #   6) Configure EXCLUSIONS_FILE to specify exclusions which will be removed from output during the JSON to CSV conversion
            #   7) Configure SCOPE_FILE to specify the file which will contain the Network Access Analyzer scope to be deployed
            #   8) Configure S3_BUCKET to specify the existing S3 bucket which will have findings uploaded to, as well as where the EXCLUSIONS_FILE may be located.
            #   9) Configure PARALLELISM for the number of accounts to process simultaneously
            #   10) Configure S3_EXCLUSION_FILE is set to true by default. This instructs the script to download the exclusion file present in s3://S3_BUCKET/EXCLUSIONS_FILE 
            #       and overwrites the local copy on EC2 upon script execution. Set to false to utilize a local exclusion file without the s3 download copy

            SPECIFIC_ACCOUNTID_LIST="allaccounts"
            #SPECIFIC_ACCOUNTID_LIST="123456789012 210987654321"

            REGION_LIST="${Regions}"
            #REGION_LIST="us-east-1 us-east-2"

            IAM_CROSS_ACCOUNT_ROLE="${IAMNAAExecRole}"

            SCRIPT_EXECUTION_MODE="CREATE_ANALYZE"

            SCOPE_NAME_VALUE="${ScopeNameValue}"

            EXCLUSIONS_FILE="${ExclusionsFile}"

            SCOPE_FILE="naa-scope.json"

            S3_BUCKET="${S3Bucket}"

            PARALLELISM="${Parallelism}"

            S3_EXCLUSION_FILE="true"
            #########################################

            #Create the network access analyzer scope JSON file
            cat << EOF > \$SCOPE_FILE
            {
                "MatchPaths": [
                    {
                        "Source": {
                            "ResourceStatement": {
                                "ResourceTypes": [
                                    "AWS::EC2::InternetGateway"
                                ]
                            }
                        },
                        "Destination": {
                            "ResourceStatement": {
                                "ResourceTypes": [
                                    "AWS::EC2::NetworkInterface"
                                ]
                            }
                        }
                    }
                ]
            }
            EOF

            #Copy EXCLUSIONS_FILE from S3 to the local EC2 if enabled.  Allows for exclusion file update within bucket and copied to EC2 upon script execution
            if [[ "\$S3_EXCLUSION_FILE" == "true" ]]; then
                echo "Copy exclusion file s3://\$S3_BUCKET/\$EXCLUSIONS_FILE to /usr/local/bin/naa"
                aws s3 cp s3://\$S3_BUCKET/\$EXCLUSIONS_FILE .
                #If an error occurs with the copy (most likely to initial execution and doens't yet exist), create a local exclusion file and copy to the S3 bucket
                if [ \$? = 1 ]; then
                    echo "There was an error copying the exclusion file s3://\$S3_BUCKET/\$EXCLUSIONS_FILE"
                    echo ""
                    echo "A local \$EXCLUSIONS_FILE will be created if it doesn't exist and copied to \$S3_BUCKET"
                    if [ ! -f \$EXCLUSIONS_FILE ]; then
                      echo "Local exclusions file file not found.  Creating..."
                      echo "resource_id,secgroup_id,sgrule_cidr,sgrule_portrange" > \$EXCLUSIONS_FILE
                    fi
                    echo "Copy exclusion file /usr/local/bin/naa/\$EXCLUSIONS_FILE to s3://\$S3_BUCKET"
                    aws s3 cp \$EXCLUSIONS_FILE s3://\$S3_BUCKET/\$EXCLUSIONS_FILE
                    if [ \$? = 1 ]; then
                      echo "There was an error copying the exclusion file \$EXCLUSIONS_FILE to the S3 Bucket \$S3_BUCKET"
                      echo "Review IAM and/or S3 bucket permissions"
                    fi
                fi
            elif [[ "\$S3_EXCLUSION_FILE" == "false" ]]; then
                #Create local exclusions file if it doesn't exist
                if [ ! -f \$EXCLUSIONS_FILE ]; then
                    echo "Local exclusions file file not found.  Creating..."
                    echo "resource_id,secgroup_id,sgrule_cidr,sgrule_portrange" > \$EXCLUSIONS_FILE
                fi
            fi

            #Create default aws cli config file with default region for commands if it doesn't exist.
            if [ ! -f ~/.aws/config ]; then
                echo ""
                echo "AWS Config file not found.  Creating..."
                aws configure set region us-east-1
            fi

            #Capture starting aws sts creds
            capture_starting_session() {
                export ORIG_AWS_ACCESS_KEY_ID=\$AWS_ACCESS_KEY_ID
                export ORIG_AWS_SECRET_ACCESS_KEY=\$AWS_SECRET_ACCESS_KEY
                export ORIG_AWS_SESSION_TOKEN=\$AWS_SESSION_TOKEN
            }
            capture_starting_session

            # Find AWS Management Account
            echo ""
            AWSMANAGEMENT=\$(aws organizations describe-organization --query Organization.MasterAccountId --output text)
            echo "AWS Management Account: \$AWSMANAGEMENT"
            echo ""

            # Function to Assume Role to Management Account and Create Session
            management_account_session() {
                echo "Assuming IAM Role in Management account to list all AWS Org accounts..."
                role_credentials=\$(aws sts assume-role --role-arn arn:aws:iam::\$AWSMANAGEMENT:role/\$IAM_CROSS_ACCOUNT_ROLE --role-session-name MgmtAccount --output json)
                AWS_ACCESS_KEY_ID=\$(echo "\$role_credentials" | jq -r .Credentials.AccessKeyId)
                AWS_SECRET_ACCESS_KEY=\$(echo "\$role_credentials" | jq -r .Credentials.SecretAccessKey)
                AWS_SESSION_TOKEN=\$(echo "\$role_credentials" | jq -r .Credentials.SessionToken)
                export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
            }

            return_starting_session() {
                export AWS_ACCESS_KEY_ID=\$ORIG_AWS_ACCESS_KEY_ID
                export AWS_SECRET_ACCESS_KEY=\$ORIG_AWS_SECRET_ACCESS_KEY
                export AWS_SESSION_TOKEN=\$ORIG_AWS_SESSION_TOKEN
            }

            execute_code() {
                #Assume role in each account
                echo "Assessing AWS Account: \$1, using Role: \$IAM_CROSS_ACCOUNT_ROLE"
                role_credentials=\$(aws sts assume-role --role-arn arn:aws:iam::\$1:role/\$IAM_CROSS_ACCOUNT_ROLE --role-session-name MgmtAccount --output json)
                AWS_ACCESS_KEY_ID=\$(echo "\$role_credentials" | jq -r .Credentials.AccessKeyId)
                AWS_SECRET_ACCESS_KEY=\$(echo "\$role_credentials" | jq -r .Credentials.SecretAccessKey)
                AWS_SESSION_TOKEN=\$(echo "\$role_credentials" | jq -r .Credentials.SessionToken)
                export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN

                #Process each region in the \$REGION_LIST array
                for region in \$REGION_LIST; do
                    {
                        echo "Processing account: \$1 / Region: \$region"

                        if [[ "\$SCRIPT_EXECUTION_MODE" == "CREATE_ANALYZE" ]]; then
                            #Create Subfolder for finding output
                            mkdir -p naaoutput

                            #Locate ScopeId and insert into variable.. Use this to discover the already existing scope for future analysis
                            echo "Account: \$1 / Region: \$region - Detecting Network Access Analyzer scope..."
                            ScopeId=\$(aws ec2 describe-network-insights-access-scopes --region \$region --filters Name=tag:Name,Values=\$SCOPE_NAME_VALUE --query 'NetworkInsightsAccessScopes[].NetworkInsightsAccessScopeId' --output text)

                            if [ -z \$ScopeId ]; then
                                #Create Scope
                                echo "Account: \$1 / Region: \$region - Network Access Analyzer scope not detected.  Creating new scope..."
                                ScopeId=\$(aws ec2 create-network-insights-access-scope --region \$region --tag-specifications "ResourceType=network-insights-access-scope,Tags=[{Key=Name,Value=\$SCOPE_NAME_VALUE}]" --cli-input-json file://\$SCOPE_FILE | jq -r '.NetworkInsightsAccessScope.NetworkInsightsAccessScopeId')
                            else
                                #Continue with Analysis of existing scope
                                echo "Account: \$1 / Region: \$region - Network Access Analyzer Scope detected."
                            fi

                            #Start Analysis and insert the AnalysisID into variable
                            echo "Account: \$1 / Region: \$region - Continuing analysis with ScopeID.  Accounts with many resources may take up to one hour"
                            AnalysisId=\$(aws ec2 --region \$region start-network-insights-access-scope-analysis --network-insights-access-scope-id \$ScopeId | jq -r '.NetworkInsightsAccessScopeAnalysis.NetworkInsightsAccessScopeAnalysisId')

                            #Monitor Status of AnalysisID.  While processing, Status is running and when done, changes to succeeded
                            i=0
                            Status="running"
                            while [ \$i -lt 240 ]
                            do
                                ((i++))
                                Status=\$(aws ec2 --region \$region describe-network-insights-access-scope-analyses --network-insights-access-scope-analysis-id \$AnalysisId | jq -r '.NetworkInsightsAccessScopeAnalyses[].Status')
                                if [[ "\$Status" != "running" ]]; then
                                    break
                                fi
                            sleep 15
                            done

                            #Proceed depending on status of the scope analysis (If \$Status == succeeded, bypass if statements)
                            if [[ "\$Status" == "running" ]]; then
                                echo "Account: \$1 / Region: \$region / AnalysisId: \$AnalysisId - Analysis timed out after 1 hour and may still be running"
                                echo "Account: \$1 / Region: \$region / AnalysisId: \$AnalysisId - Please review and execute again later"
                                return 0
                            elif [[ "\$Status" == "failed" ]]; then
                                AnalysisStatus=\$(aws ec2 --region \$region describe-network-insights-access-scope-analyses --network-insights-access-scope-analysis-id \$AnalysisId | jq -r '.NetworkInsightsAccessScopeAnalyses[].StatusMessage')
                                echo "Account: \$1 / Region: \$region / AnalysisId: \$AnalysisId - Analysis failed to complete. Please review"
                                echo "Account: \$1 / Region: \$region / AnalysisId: \$AnalysisId - Status Message: \$AnalysisStatus"
                                return 0
                            fi

                            #Output findings from Analysis in JSON format.
                            echo "Account: \$1 / Region: \$region - Outputting findings..."
                            aws ec2 --region \$region get-network-insights-access-scope-analysis-findings --network-insights-access-scope-analysis-id \$AnalysisId --no-cli-pager > naaoutput/naa-unprocessed-\$1-\$region.json

                        elif [[ "\$SCRIPT_EXECUTION_MODE" == "DELETE" ]]; then
                            #Locate ScopeId and insert into variable.. Use this to discover the already existing scope for future analysis
                            ScopeId=\$(aws ec2 describe-network-insights-access-scopes --region \$region --filters Name=tag:Name,Values=\$SCOPE_NAME_VALUE --query 'NetworkInsightsAccessScopes[].NetworkInsightsAccessScopeId' --output text)

                            #Validate NAA Scope exists.  If not, exit loop
                            if [ -z \$ScopeId ]; then
                                continue
                            fi

                            #Generate AnalysisIdList and build space separated list
                            AnalysisIdList=\$(aws ec2 describe-network-insights-access-scope-analyses --region \$region --network-insights-access-scope-id \$ScopeId | jq -r '.NetworkInsightsAccessScopeAnalyses[].NetworkInsightsAccessScopeAnalysisId' |tr "\n" " ")

                            #Delete each AnalysisId from the list
                            for AnalysisId in \$AnalysisIdList; do
                                {
                                    #Delete AnalysisId associated with Scope
                                    echo "Account: \$1 / Region: \$region - Deleting Analysis \$AnalysisId"
                                    aws ec2 delete-network-insights-access-scope-analysis --region \$region --network-insights-access-scope-analysis-id \$AnalysisId
                                }
                            done

                            #Delete Scope
                            echo "Account: \$1 / Region: \$region - Deleting Scope \$ScopeId"
                            aws ec2 delete-network-insights-access-scope --region \$region --network-insights-access-scope-id \$ScopeId
                        fi
                    }
                done

                echo "Account: \$1 / Region: \$region - Completed"
                echo ""
                echo ""

                #Return to original credentials
                return_starting_session
            }

            #Monitor the number of background processes and return to task execution for loop when bg jobs less than PARALLELISM limit
            process_monitor() {
                while [ "\$(jobs | wc -l)" -ge \$PARALLELISM ]
                do
                    sleep 2
                done
            }

            if [[ "\$SPECIFIC_ACCOUNTID_LIST" == "allaccounts" ]]; then
                # Lookup All Accounts in AWS Organization
                management_account_session
                ACCOUNTS_TO_PROCESS=\$(aws organizations list-accounts --output text --query 'Accounts[?Status==\`ACTIVE\`].Id')
                echo ""

                # Return to original credentials after generating list of AWS accounts
                return_starting_session
            else
                ACCOUNTS_TO_PROCESS=\$SPECIFIC_ACCOUNTID_LIST
            fi

            # Execute command against accounts
            echo ""
            echo "AWS Accounts being processed..."
            echo "\$ACCOUNTS_TO_PROCESS"
            echo ""

            #Process all accounts in the \$ACCOUNTS_TO_PROCESS array, 8 at a time, and send them to the background
            for accountId in \$ACCOUNTS_TO_PROCESS; do
                test "\$(jobs | wc -l)" -ge \$PARALLELISM && process_monitor || true
                {
                    execute_code \$accountId
                } &
            done

            # Wait for all background processes to finish
            wait

            ####
            #### POST ACCOUNT AND REGION EXECUTION: COMMAND(S) BELOW TO BE EXECUTED ON RESULTS
            ####

            #Set variable with timestamp for use with file generation
            OUTPUT_SUFFIX=\$(date +%m-%d-%Y-%H-%M)

            if [[ "\$SCRIPT_EXECUTION_MODE" == "CREATE_ANALYZE" ]]; then
                echo ""
                echo "Network Access Analyzer assessments have been completed against all accounts"
                echo ""
                echo "Proceeding to Post Processing"
                echo ""

                #Remove previously processed data and zip
                rm -f naaoutput/naa-findings*.csv naaoutput/naa-unprocessed*.zip

                #Generate a list of individual output files and process them into csv with python
                FINDING_FILES=\$(ls naaoutput/naa-unprocessed*.json)

                #Loop through files and process from json into csv
                for finding in \$FINDING_FILES; do
                    {
                        echo "Processing file: \$finding" | tee -a naaoutput/naa-findings2csvresults.txt
                        python3 ./naa-findings2csv.py  -i \$finding -o naaoutput/naa-findings-\$OUTPUT_SUFFIX.csv -e \$EXCLUSIONS_FILE >> naaoutput/naa-findings2csvresults.txt 2>&1
                    }
                done

                #Zip all individual findings into single file for archive
                echo ""
                echo "Zip files"
                zip naaoutput/naa-unprocessed-\$OUTPUT_SUFFIX.zip naaoutput/naa-unprocessed*.json naaoutput/naa-findings2csvresults.txt

                #Remove unprocessed finding files which now exist within the zip file
                rm -f naaoutput/naa-unprocessed-*.json naaoutput/naa-findings2csvresults.txt

                #Copy zip file to S3 bucket
                aws s3 cp ./naaoutput s3://\$S3_BUCKET --recursive --exclude "*" --include "naa*.zip" --include "naa-findings*.csv"

                echo ""
                echo "view output at command line with:"
                echo "column -s, -t < naaoutput/naa-findings-\$OUTPUT_SUFFIX.csv | less -#2 -N -S"
            fi

            echo ""
            echo "Processing has been executed against all accounts in the AWS account list"
            echo ""
            EOL
            
            chmod +x /usr/local/bin/naa/naa-script.sh

            #Set cron if ScheduledAnalysis == true and use the CronScheduleExpression value
            if [[ "${ScheduledAnalysis}" == "true" ]]; then
              echo "${CronScheduleExpression} root BASH_ENV=/etc/profile /usr/local/bin/naa/naa-script.sh" > /etc/cron.d/naa-schedule
            fi
            
      Tags:
        - Key: "Name"
          Value: "naaec2"

Outputs:
  NAAEC2Role:
    Description: The ARN of the NAAEC2Role
    Value: !GetAtt NAAEC2Role.Arn
